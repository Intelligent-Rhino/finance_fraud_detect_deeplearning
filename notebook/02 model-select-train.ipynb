{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c449e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir ='../'\n",
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93eb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c507b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model_checkpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62016e9f",
   "metadata": {},
   "source": [
    "### load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b900cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd389c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e3edc",
   "metadata": {},
   "source": [
    "### load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51585caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path ='./data/trainset-281-29.xlsx'\n",
    "train_df = pd.read_excel(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b119d21",
   "metadata": {},
   "source": [
    "### feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c82656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import processing\n",
    "\n",
    "p_conn =processing.processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfc855",
   "metadata": {},
   "source": [
    "#### missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2521ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value =-999\n",
    "missing_label ='missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c9da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    train_df[col] =train_df[col].apply(lambda x : None if str.lower(str(x)) in ['none','non','nan'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9042781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e1d53",
   "metadata": {},
   "source": [
    "#### discrete features -more than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f60f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cols_over_10 =['CARR_NAME','RGN_NAME','STATE_PRVNC_TXT','CUST_STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cdb48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_map =pickle.load(open(f\"{model_dir}/risk_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0330d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...CARR_NAME\n",
      "...RGN_NAME\n",
      "...STATE_PRVNC_TXT\n",
      "...CUST_STATE\n"
     ]
    }
   ],
   "source": [
    "# reduce dimension with risk ratio\n",
    "for idx,col in enumerate(discrete_cols_over_10):\n",
    "    print(f\"...{col}\")\n",
    "    target_col = f\"{col}_bin_10_feature\"\n",
    "    value_map =risk_map[col]\n",
    "    train_df[target_col] = train_df[col].apply(lambda x : value_map.get(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6cb965",
   "metadata": {},
   "source": [
    "####  discrete features -less than 10\n",
    "\n",
    "    none treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ee534",
   "metadata": {},
   "source": [
    "#### datetime formate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965d24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cols =['PWD_UPDT_TS','PH_NUM_UPDT_TS', 'TRAN_TS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf2c54",
   "metadata": {},
   "source": [
    "##### operating hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36adc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(ts_cols):\n",
    "    target_col = f\"{col}_hour\"\n",
    "    train_df = p_conn.operate_hour(train_df,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3c897",
   "metadata": {},
   "source": [
    "##### gap between updating operation, like passwaor or phone number,and transaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18abaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['PWD_UPDT_TS_day'] = train_df.apply(lambda x : p_conn.timedelta_day(x.TRAN_TS,x.PWD_UPDT_TS),axis =1)    \n",
    "train_df['PH_NUM_UPDT_TS_day'] = train_df.apply(lambda x : p_conn.timedelta_day(x.TRAN_TS,x.PH_NUM_UPDT_TS),axis =1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33862d0",
   "metadata": {},
   "source": [
    "### feature label to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "419d6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_value_idx_map =pickle.load(open(f'{model_dir}/txt_value_idx_map.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d397fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features =['CARR_NAME_bin_10_feature','PH_NUM_UPDT_TS_hour','RGN_NAME_bin_10_feature',\n",
    "                   'STATE_PRVNC_TXT_bin_10_feature','PWD_UPDT_TS_hour','PH_NUM_UPDT_TS_day','DVC_TYPE_TXT']\n",
    "\n",
    "continuous_features =['ACCT_PRE_TRAN_AVAIL_BAL','TRAN_AMT','OPEN_ACCT_CT','WF_dvc_age',]\n",
    "\n",
    "\n",
    "filterd_features = discrete_features+continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51826660",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in discrete_features:\n",
    "    train_df[col] = train_df[col].apply(lambda x : txt_value_idx_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41b736",
   "metadata": {},
   "source": [
    "### model select & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e8459c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b59e9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "label ='FRAUD_NONFRAUD'\n",
    "label_map ={'Fraud':1,'Non-Fraud':0}\n",
    "\n",
    "\n",
    "xgb_df =copy.deepcopy(train_df[filterd_features+[label]])\n",
    "\n",
    "train_x,test_x = train_test_split(xgb_df,\n",
    "                                 test_size=0.3,\n",
    "                                 shuffle=True)\n",
    "\n",
    "\n",
    "train_x =pd.concat([train_x,train_x[train_x['FRAUD_NONFRAUD']=='Fraud']])\n",
    "\n",
    "train_x = train_x.sample(frac=1)\n",
    "\n",
    "train_y =train_x.pop('FRAUD_NONFRAUD')\n",
    "train_y =[label_map.get(i) for i in train_y ]\n",
    "\n",
    "\n",
    "test_y =test_x.pop('FRAUD_NONFRAUD')\n",
    "test_y =[label_map.get(i) for i in test_y ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1249b2b",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328fee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1e5e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....random forest classification report---training dataset\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      6869\n",
      "           1       0.98      0.98      0.98      5862\n",
      "\n",
      "    accuracy                           0.98     12731\n",
      "   macro avg       0.98      0.98      0.98     12731\n",
      "weighted avg       0.98      0.98      0.98     12731\n",
      "\n",
      "....random forest classification report---test dataset\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      2967\n",
      "           1       0.91      0.95      0.93      1233\n",
      "\n",
      "    accuracy                           0.96      4200\n",
      "   macro avg       0.95      0.96      0.95      4200\n",
      "weighted avg       0.96      0.96      0.96      4200\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "feature importance\n",
      "{'CARR_NAME_bin_10_feature': 0.16296522285073528, 'PH_NUM_UPDT_TS_hour': 0.013030193444410981, 'RGN_NAME_bin_10_feature': 0.06049434386265044, 'STATE_PRVNC_TXT_bin_10_feature': 0.07740889035292757, 'PWD_UPDT_TS_hour': 0.009048560694183116, 'PH_NUM_UPDT_TS_day': 0.02853936458405642, 'DVC_TYPE_TXT': 0.014148291727845217, 'ACCT_PRE_TRAN_AVAIL_BAL': 0.1368777047383855, 'TRAN_AMT': 0.4280444361120025, 'OPEN_ACCT_CT': 0.013001150581838086, 'WF_dvc_age': 0.056441841050964905}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=10, random_state =2021)\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# train dataset\n",
    "predict_train_y = clf.predict(train_x)\n",
    "predict_train_y =predict_train_y.tolist()\n",
    "print(f\"....random forest classification report---training dataset\")\n",
    "print('\\n')\n",
    "print(classification_report(y_true=train_y,y_pred=predict_train_y))\n",
    "\n",
    "# test dataset\n",
    "predict_y = clf.predict(test_x)\n",
    "predict_y =predict_y.tolist()\n",
    "print(f\"....random forest classification report---test dataset\")\n",
    "print('\\n')\n",
    "print(classification_report(y_true=test_y,y_pred=predict_y))\n",
    "\n",
    "print('++'*40)\n",
    "\n",
    "print(f\"feature importance\")\n",
    "\n",
    "print(dict(zip(filterd_features,clf.feature_importances_.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a9cec",
   "metadata": {},
   "source": [
    "####  save model -random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5bbbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(f\"{model_dir}/randomforest.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe160f61",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "129360a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4abe7d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mining/Library/Python/3.8/lib/python/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=0.7, subsample=0.7,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres =0.5\n",
    "\n",
    "bst =xgb.XGBClassifier(base_score=thres,\n",
    "                       scale_pos_weight=0.7,\n",
    "                       min_child_weight=10,\n",
    "                       subsample =0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                      max_depth =8)\n",
    "\n",
    "bst.fit(train_x.to_numpy(),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e79ec28f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....xgboost classification report---training dataset\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6869\n",
      "           1       0.99      0.98      0.99      5862\n",
      "\n",
      "    accuracy                           0.99     12731\n",
      "   macro avg       0.99      0.99      0.99     12731\n",
      "weighted avg       0.99      0.99      0.99     12731\n",
      "\n",
      "....xgboost classification report---testing dataset\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2967\n",
      "           1       0.94      0.95      0.95      1233\n",
      "\n",
      "    accuracy                           0.97      4200\n",
      "   macro avg       0.96      0.96      0.96      4200\n",
      "weighted avg       0.97      0.97      0.97      4200\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "feature importance\n",
      "{'CARR_NAME_bin_10_feature': 0.32374516129493713, 'PH_NUM_UPDT_TS_hour': 0.02467169798910618, 'RGN_NAME_bin_10_feature': 0.0574461966753006, 'STATE_PRVNC_TXT_bin_10_feature': 0.04166004806756973, 'PWD_UPDT_TS_hour': 0.032499708235263824, 'PH_NUM_UPDT_TS_day': 0.07760666310787201, 'DVC_TYPE_TXT': 0.060777150094509125, 'ACCT_PRE_TRAN_AVAIL_BAL': 0.0696987509727478, 'TRAN_AMT': 0.23868322372436523, 'OPEN_ACCT_CT': 0.021808866411447525, 'WF_dvc_age': 0.05140262842178345}\n"
     ]
    }
   ],
   "source": [
    "# training dataset\n",
    "# predict_train_y = bst.predict(dtrain)\n",
    "predict_train_y = bst.predict(train_x)\n",
    "\n",
    "predict_train_y =predict_train_y.tolist()\n",
    "predict_train_y =[1 if i >=thres else 0 for i in predict_train_y]\n",
    "print(f\"....xgboost classification report---training dataset\")\n",
    "print('\\n')\n",
    "print(classification_report(y_true=train_y,y_pred=predict_train_y))\n",
    "\n",
    "\n",
    "predict_y_xgb = bst.predict(test_x)\n",
    "predict_y_xgb =predict_y_xgb.tolist()\n",
    "predict_y_xgb =[1 if i >=thres else 0 for i in predict_y_xgb]\n",
    "print(f\"....xgboost classification report---testing dataset\")\n",
    "print('\\n')\n",
    "print(classification_report(y_true=test_y,y_pred=predict_y_xgb))\n",
    "\n",
    "\n",
    "print('++'*40)\n",
    "\n",
    "print(f\"feature importance\")\n",
    "\n",
    "print(dict(zip(filterd_features,bst.feature_importances_.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70dcf06",
   "metadata": {},
   "source": [
    "#### save model- xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efbecb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bst, open(f\"{model_dir}/bst.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df419f7a",
   "metadata": {},
   "source": [
    "##### DeepFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fecfdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from deepctrmodels.deepfm import Deepfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7b3d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features =['ACCT_PRE_TRAN_AVAIL_BAL', 'OPEN_ACCT_CT', 'TRAN_AMT', 'WF_dvc_age']\n",
    "sparse_features =list(set(filterd_features)- set(dense_features))\n",
    "\n",
    "feature_names =filterd_features\n",
    "target = ['FRAUD_NONFRAUD']                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ecff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1024\n",
    "torch.manual_seed(seed)  \n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bceaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xx = copy.deepcopy(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "101ddab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(-1, 1))\n",
    "for df in [train_x,test_xx]:\n",
    "    df[dense_features] = mms.fit_transform(df[dense_features])\n",
    "\n",
    "# test_xx[dense_features] =mms.transform(test_xx[dense_features])\n",
    "\n",
    "pickle.dump(mms, open(f\"{model_dir}/max_min_scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45bf38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "feat_sizes1={ feat:1 for feat in dense_features}\n",
    "feat_sizes2 = {feat: max(txt_value_idx_map.values())+1 for feat in sparse_features}\n",
    "\n",
    "# feat_sizes2 = {feat: len(train_df[feat].unique()) for feat in sparse_features}\n",
    "feat_sizes={}\n",
    "feat_sizes.update(feat_sizes1)\n",
    "feat_sizes.update(feat_sizes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "817c671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_input = {name: train_x[name] for name in feature_names}\n",
    "test_model_input =  {name: test_xx[name]  for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8221fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Define Model,train,predict and evaluate\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = Deepfm(feat_sizes ,\n",
    "               sparse_feature_columns = sparse_features,\n",
    "               sparse_shared_embedding_map ={},\n",
    "               dense_feature_columns = dense_features,\n",
    "               model_checkpoint_path =f\"{model_dir}/deepfm.pt\",\n",
    "               dnn_hidden_units=[32,16] , dnn_dropout=0.5 , ebedding_size = 10,\n",
    "               l2_reg_linear=1e-3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "990262f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 12731 samples,  50 steps per epoch\n",
      "epoch 0 train loss is 0.6394 train AUC is 0.8413\n",
      "test LogLoss is 0.5526 test AUC is 0.9093\n",
      "f1_score :0.8318708792849314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2967\n",
      "           1       0.71      0.73      0.72      1233\n",
      "\n",
      "    accuracy                           0.83      4200\n",
      "   macro avg       0.80      0.80      0.80      4200\n",
      "weighted avg       0.83      0.83      0.83      4200\n",
      "\n",
      "epoch 1 train loss is 0.4716 train AUC is 0.8884\n",
      "test LogLoss is 0.4055 test AUC is 0.9062\n",
      "f1_score :0.8311132520920345\n",
      "epoch 2 train loss is 0.3784 train AUC is 0.9240\n",
      "test LogLoss is 0.3501 test AUC is 0.9241\n",
      "f1_score :0.8587791160759275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      2967\n",
      "           1       0.74      0.79      0.77      1233\n",
      "\n",
      "    accuracy                           0.86      4200\n",
      "   macro avg       0.83      0.84      0.83      4200\n",
      "weighted avg       0.86      0.86      0.86      4200\n",
      "\n",
      "epoch 3 train loss is 0.3330 train AUC is 0.9387\n",
      "test LogLoss is 0.3162 test AUC is 0.9350\n",
      "f1_score :0.8723170101801572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      2967\n",
      "           1       0.76      0.83      0.79      1233\n",
      "\n",
      "    accuracy                           0.87      4200\n",
      "   macro avg       0.84      0.86      0.85      4200\n",
      "weighted avg       0.88      0.87      0.87      4200\n",
      "\n",
      "epoch 4 train loss is 0.3089 train AUC is 0.9465\n",
      "test LogLoss is 0.3017 test AUC is 0.9399\n",
      "f1_score :0.8751342175066313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2967\n",
      "           1       0.76      0.84      0.80      1233\n",
      "\n",
      "    accuracy                           0.87      4200\n",
      "   macro avg       0.84      0.86      0.85      4200\n",
      "weighted avg       0.88      0.87      0.88      4200\n",
      "\n",
      "epoch 5 train loss is 0.2972 train AUC is 0.9498\n",
      "test LogLoss is 0.2910 test AUC is 0.9434\n",
      "f1_score :0.877457861320645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2967\n",
      "           1       0.76      0.84      0.80      1233\n",
      "\n",
      "    accuracy                           0.88      4200\n",
      "   macro avg       0.85      0.87      0.85      4200\n",
      "weighted avg       0.88      0.88      0.88      4200\n",
      "\n",
      "epoch 6 train loss is 0.2912 train AUC is 0.9516\n",
      "test LogLoss is 0.2764 test AUC is 0.9463\n",
      "f1_score :0.8817609293543351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      2967\n",
      "           1       0.78      0.83      0.80      1233\n",
      "\n",
      "    accuracy                           0.88      4200\n",
      "   macro avg       0.85      0.87      0.86      4200\n",
      "weighted avg       0.88      0.88      0.88      4200\n",
      "\n",
      "epoch 7 train loss is 0.2841 train AUC is 0.9541\n",
      "test LogLoss is 0.2884 test AUC is 0.9487\n",
      "f1_score :0.8805214778436535\n",
      "epoch 8 train loss is 0.2790 train AUC is 0.9561\n",
      "test LogLoss is 0.2730 test AUC is 0.9506\n",
      "f1_score :0.8821077403272175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      2967\n",
      "           1       0.76      0.86      0.81      1233\n",
      "\n",
      "    accuracy                           0.88      4200\n",
      "   macro avg       0.85      0.87      0.86      4200\n",
      "weighted avg       0.89      0.88      0.88      4200\n",
      "\n",
      "epoch 9 train loss is 0.2741 train AUC is 0.9577\n",
      "test LogLoss is 0.2699 test AUC is 0.9523\n",
      "f1_score :0.8839085155475559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      2967\n",
      "           1       0.76      0.87      0.81      1233\n",
      "\n",
      "    accuracy                           0.88      4200\n",
      "   macro avg       0.85      0.88      0.86      4200\n",
      "weighted avg       0.89      0.88      0.88      4200\n",
      "\n",
      "epoch 10 train loss is 0.2702 train AUC is 0.9591\n",
      "test LogLoss is 0.2627 test AUC is 0.9535\n",
      "f1_score :0.8867953053241472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92      2967\n",
      "           1       0.77      0.86      0.82      1233\n",
      "\n",
      "    accuracy                           0.89      4200\n",
      "   macro avg       0.86      0.88      0.87      4200\n",
      "weighted avg       0.89      0.89      0.89      4200\n",
      "\n",
      "epoch 11 train loss is 0.2657 train AUC is 0.9605\n",
      "test LogLoss is 0.2692 test AUC is 0.9553\n",
      "f1_score :0.881711108610268\n",
      "epoch 12 train loss is 0.2625 train AUC is 0.9616\n",
      "test LogLoss is 0.2661 test AUC is 0.9568\n",
      "f1_score :0.881192621560767\n",
      "epoch 13 train loss is 0.2597 train AUC is 0.9626\n",
      "test LogLoss is 0.2617 test AUC is 0.9580\n",
      "f1_score :0.8837044073579834\n",
      "epoch 14 train loss is 0.2570 train AUC is 0.9635\n",
      "test LogLoss is 0.2546 test AUC is 0.9584\n",
      "f1_score :0.8855282770039821\n",
      "epoch 15 train loss is 0.2543 train AUC is 0.9643\n",
      "test LogLoss is 0.2491 test AUC is 0.9589\n",
      "f1_score :0.8885640253191022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      2967\n",
      "           1       0.77      0.88      0.82      1233\n",
      "\n",
      "    accuracy                           0.89      4200\n",
      "   macro avg       0.86      0.89      0.87      4200\n",
      "weighted avg       0.89      0.89      0.89      4200\n",
      "\n",
      "epoch 16 train loss is 0.2535 train AUC is 0.9644\n",
      "test LogLoss is 0.2569 test AUC is 0.9601\n",
      "f1_score :0.8859832010207794\n",
      "epoch 17 train loss is 0.2515 train AUC is 0.9651\n",
      "test LogLoss is 0.2529 test AUC is 0.9600\n",
      "f1_score :0.8860303192108238\n",
      "epoch 18 train loss is 0.2500 train AUC is 0.9657\n",
      "test LogLoss is 0.2432 test AUC is 0.9599\n",
      "f1_score :0.8923345103868462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      2967\n",
      "           1       0.78      0.88      0.83      1233\n",
      "\n",
      "    accuracy                           0.89      4200\n",
      "   macro avg       0.86      0.89      0.87      4200\n",
      "weighted avg       0.90      0.89      0.89      4200\n",
      "\n",
      "epoch 19 train loss is 0.2492 train AUC is 0.9657\n",
      "test LogLoss is 0.2499 test AUC is 0.9609\n",
      "f1_score :0.8892160428831244\n",
      "epoch 20 train loss is 0.2474 train AUC is 0.9662\n",
      "test LogLoss is 0.2449 test AUC is 0.9615\n",
      "f1_score :0.8915899161035674\n",
      "epoch 21 train loss is 0.2468 train AUC is 0.9664\n",
      "test LogLoss is 0.2453 test AUC is 0.9620\n",
      "f1_score :0.8921277599066646\n",
      "epoch 22 train loss is 0.2456 train AUC is 0.9667\n",
      "test LogLoss is 0.2558 test AUC is 0.9616\n",
      "f1_score :0.889988800204054\n",
      "epoch 23 train loss is 0.2457 train AUC is 0.9667\n",
      "test LogLoss is 0.2499 test AUC is 0.9619\n",
      "f1_score :0.8929741019214703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      2967\n",
      "           1       0.76      0.91      0.83      1233\n",
      "\n",
      "    accuracy                           0.89      4200\n",
      "   macro avg       0.86      0.90      0.87      4200\n",
      "weighted avg       0.90      0.89      0.89      4200\n",
      "\n",
      "epoch 24 train loss is 0.2454 train AUC is 0.9667\n",
      "test LogLoss is 0.2455 test AUC is 0.9623\n",
      "f1_score :0.8930065972328322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      2967\n",
      "           1       0.77      0.90      0.83      1233\n",
      "\n",
      "    accuracy                           0.89      4200\n",
      "   macro avg       0.86      0.89      0.87      4200\n",
      "weighted avg       0.90      0.89      0.89      4200\n",
      "\n",
      "epoch 25 train loss is 0.2440 train AUC is 0.9671\n",
      "test LogLoss is 0.2401 test AUC is 0.9624\n",
      "f1_score :0.8964342034213663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      2967\n",
      "           1       0.78      0.89      0.83      1233\n",
      "\n",
      "    accuracy                           0.89      4200\n",
      "   macro avg       0.87      0.89      0.88      4200\n",
      "weighted avg       0.90      0.89      0.90      4200\n",
      "\n",
      "epoch 26 train loss is 0.2435 train AUC is 0.9673\n",
      "test LogLoss is 0.2415 test AUC is 0.9625\n",
      "f1_score :0.895086987115709\n",
      "epoch 27 train loss is 0.2426 train AUC is 0.9674\n",
      "test LogLoss is 0.2437 test AUC is 0.9621\n",
      "f1_score :0.8959052250964658\n",
      "epoch 28 train loss is 0.2421 train AUC is 0.9676\n",
      "test LogLoss is 0.2448 test AUC is 0.9630\n",
      "f1_score :0.8952850443242311\n",
      "epoch 29 train loss is 0.2418 train AUC is 0.9677\n",
      "test LogLoss is 0.2416 test AUC is 0.9620\n",
      "f1_score :0.8975940373327992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      2967\n",
      "           1       0.78      0.89      0.83      1233\n",
      "\n",
      "    accuracy                           0.90      4200\n",
      "   macro avg       0.87      0.90      0.88      4200\n",
      "weighted avg       0.90      0.90      0.90      4200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 train loss is 0.2420 train AUC is 0.9677\n",
      "test LogLoss is 0.2323 test AUC is 0.9624\n",
      "f1_score :0.900612219015868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.80      0.88      0.84      1233\n",
      "\n",
      "    accuracy                           0.90      4200\n",
      "   macro avg       0.87      0.89      0.88      4200\n",
      "weighted avg       0.90      0.90      0.90      4200\n",
      "\n",
      "epoch 31 train loss is 0.2421 train AUC is 0.9675\n",
      "test LogLoss is 0.2395 test AUC is 0.9632\n",
      "f1_score :0.8985651389509576\n",
      "epoch 32 train loss is 0.2409 train AUC is 0.9679\n",
      "test LogLoss is 0.2410 test AUC is 0.9632\n",
      "f1_score :0.8986360997893492\n",
      "epoch 33 train loss is 0.2406 train AUC is 0.9680\n",
      "test LogLoss is 0.2370 test AUC is 0.9634\n",
      "f1_score :0.8996355414952261\n",
      "epoch 34 train loss is 0.2409 train AUC is 0.9680\n",
      "test LogLoss is 0.2353 test AUC is 0.9632\n",
      "f1_score :0.8999760879538653\n",
      "epoch 35 train loss is 0.2401 train AUC is 0.9682\n",
      "test LogLoss is 0.2474 test AUC is 0.9635\n",
      "f1_score :0.8968213001442259\n",
      "epoch 36 train loss is 0.2394 train AUC is 0.9684\n",
      "test LogLoss is 0.2324 test AUC is 0.9632\n",
      "f1_score :0.9008952332791921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.80      0.88      0.84      1233\n",
      "\n",
      "    accuracy                           0.90      4200\n",
      "   macro avg       0.87      0.89      0.88      4200\n",
      "weighted avg       0.90      0.90      0.90      4200\n",
      "\n",
      "epoch 37 train loss is 0.2395 train AUC is 0.9684\n",
      "test LogLoss is 0.2380 test AUC is 0.9636\n",
      "f1_score :0.9003284252458303\n",
      "epoch 38 train loss is 0.2394 train AUC is 0.9685\n",
      "test LogLoss is 0.2383 test AUC is 0.9636\n",
      "f1_score :0.9001213638374497\n",
      "epoch 39 train loss is 0.2389 train AUC is 0.9686\n",
      "test LogLoss is 0.2326 test AUC is 0.9641\n",
      "f1_score :0.9027148805276055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.80      0.89      0.84      1233\n",
      "\n",
      "    accuracy                           0.90      4200\n",
      "   macro avg       0.87      0.90      0.88      4200\n",
      "weighted avg       0.91      0.90      0.90      4200\n",
      "\n",
      "epoch 40 train loss is 0.2390 train AUC is 0.9686\n",
      "test LogLoss is 0.2462 test AUC is 0.9637\n",
      "f1_score :0.8979271325689234\n",
      "epoch 41 train loss is 0.2383 train AUC is 0.9687\n",
      "test LogLoss is 0.2358 test AUC is 0.9640\n",
      "f1_score :0.9014537277995166\n",
      "epoch 42 train loss is 0.2380 train AUC is 0.9688\n",
      "test LogLoss is 0.2286 test AUC is 0.9637\n",
      "f1_score :0.9047668307973549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.81      0.88      0.84      1233\n",
      "\n",
      "    accuracy                           0.90      4200\n",
      "   macro avg       0.88      0.90      0.89      4200\n",
      "weighted avg       0.91      0.90      0.90      4200\n",
      "\n",
      "epoch 43 train loss is 0.2378 train AUC is 0.9689\n",
      "test LogLoss is 0.2297 test AUC is 0.9636\n",
      "f1_score :0.9036760611115172\n",
      "epoch 44 train loss is 0.2375 train AUC is 0.9690\n",
      "test LogLoss is 0.2460 test AUC is 0.9642\n",
      "f1_score :0.8965799391980023\n",
      "epoch 45 train loss is 0.2379 train AUC is 0.9688\n",
      "test LogLoss is 0.2321 test AUC is 0.9642\n",
      "f1_score :0.9036164282737289\n",
      "epoch 46 train loss is 0.2394 train AUC is 0.9685\n",
      "test LogLoss is 0.2444 test AUC is 0.9632\n",
      "f1_score :0.9012986128847654\n",
      "epoch 47 train loss is 0.2383 train AUC is 0.9688\n",
      "test LogLoss is 0.2326 test AUC is 0.9638\n",
      "f1_score :0.9022093688324696\n",
      "epoch 48 train loss is 0.2371 train AUC is 0.9691\n",
      "test LogLoss is 0.2386 test AUC is 0.9646\n",
      "f1_score :0.9023389757412399\n",
      "epoch 49 train loss is 0.2362 train AUC is 0.9693\n",
      "test LogLoss is 0.2369 test AUC is 0.9648\n",
      "f1_score :0.9024952509768952\n",
      "epoch 50 train loss is 0.2364 train AUC is 0.9694\n",
      "test LogLoss is 0.2360 test AUC is 0.9644\n",
      "f1_score :0.9035691701725664\n",
      "epoch 51 train loss is 0.2360 train AUC is 0.9695\n",
      "test LogLoss is 0.2406 test AUC is 0.9642\n",
      "f1_score :0.9014898483141652\n",
      "epoch 52 train loss is 0.2358 train AUC is 0.9696\n",
      "test LogLoss is 0.2383 test AUC is 0.9645\n",
      "f1_score :0.9023046729988485\n",
      "epoch 53 train loss is 0.2362 train AUC is 0.9694\n",
      "test LogLoss is 0.2376 test AUC is 0.9645\n",
      "f1_score :0.9032053229583994\n",
      "epoch 54 train loss is 0.2357 train AUC is 0.9696\n",
      "test LogLoss is 0.2338 test AUC is 0.9648\n",
      "f1_score :0.902425370074244\n",
      "epoch 55 train loss is 0.2356 train AUC is 0.9696\n",
      "test LogLoss is 0.2293 test AUC is 0.9649\n",
      "f1_score :0.9031474084599761\n",
      "epoch 56 train loss is 0.2352 train AUC is 0.9697\n",
      "test LogLoss is 0.2285 test AUC is 0.9648\n",
      "f1_score :0.9047439836149513\n",
      "epoch 57 train loss is 0.2349 train AUC is 0.9698\n",
      "test LogLoss is 0.2326 test AUC is 0.9641\n",
      "f1_score :0.902397776314827\n",
      "epoch 58 train loss is 0.2350 train AUC is 0.9698\n",
      "test LogLoss is 0.2353 test AUC is 0.9645\n",
      "f1_score :0.9010746832969386\n",
      "epoch 59 train loss is 0.2354 train AUC is 0.9696\n",
      "test LogLoss is 0.2348 test AUC is 0.9649\n",
      "f1_score :0.9035340621955252\n",
      "epoch 60 train loss is 0.2336 train AUC is 0.9702\n",
      "test LogLoss is 0.2311 test AUC is 0.9650\n",
      "f1_score :0.9039671450512146\n",
      "epoch 61 train loss is 0.2346 train AUC is 0.9701\n",
      "test LogLoss is 0.2291 test AUC is 0.9649\n",
      "f1_score :0.9042928779746632\n",
      "epoch 62 train loss is 0.2346 train AUC is 0.9700\n",
      "test LogLoss is 0.2323 test AUC is 0.9653\n",
      "f1_score :0.9040372809969716\n",
      "epoch 63 train loss is 0.2333 train AUC is 0.9703\n",
      "test LogLoss is 0.2317 test AUC is 0.9655\n",
      "f1_score :0.9035691701725664\n",
      "epoch 64 train loss is 0.2329 train AUC is 0.9704\n",
      "test LogLoss is 0.2250 test AUC is 0.9648\n",
      "f1_score :0.9051236872439016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.81      0.88      0.84      1233\n",
      "\n",
      "    accuracy                           0.90      4200\n",
      "   macro avg       0.88      0.90      0.89      4200\n",
      "weighted avg       0.91      0.90      0.91      4200\n",
      "\n",
      "epoch 65 train loss is 0.2334 train AUC is 0.9703\n",
      "test LogLoss is 0.2313 test AUC is 0.9651\n",
      "f1_score :0.9043647624002019\n",
      "epoch 66 train loss is 0.2338 train AUC is 0.9703\n",
      "test LogLoss is 0.2304 test AUC is 0.9651\n",
      "f1_score :0.9050413266116571\n",
      "epoch 67 train loss is 0.2324 train AUC is 0.9705\n",
      "test LogLoss is 0.2276 test AUC is 0.9656\n",
      "f1_score :0.9063952046820428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.80      0.89      0.85      1233\n",
      "\n",
      "    accuracy                           0.91      4200\n",
      "   macro avg       0.88      0.90      0.89      4200\n",
      "weighted avg       0.91      0.91      0.91      4200\n",
      "\n",
      "epoch 68 train loss is 0.2328 train AUC is 0.9704\n",
      "test LogLoss is 0.2348 test AUC is 0.9652\n",
      "f1_score :0.9040546522265175\n",
      "epoch 69 train loss is 0.2327 train AUC is 0.9705\n",
      "test LogLoss is 0.2293 test AUC is 0.9653\n",
      "f1_score :0.9052490757598501\n",
      "epoch 70 train loss is 0.2320 train AUC is 0.9707\n",
      "test LogLoss is 0.2291 test AUC is 0.9654\n",
      "f1_score :0.9044355980021841\n",
      "epoch 71 train loss is 0.2321 train AUC is 0.9707\n",
      "test LogLoss is 0.2376 test AUC is 0.9658\n",
      "f1_score :0.9021479505286206\n",
      "epoch 72 train loss is 0.2316 train AUC is 0.9708\n",
      "test LogLoss is 0.2371 test AUC is 0.9658\n",
      "f1_score :0.9027892165484239\n",
      "epoch 73 train loss is 0.2323 train AUC is 0.9707\n",
      "test LogLoss is 0.2247 test AUC is 0.9656\n",
      "f1_score :0.9078689809460643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2967\n",
      "           1       0.81      0.89      0.85      1233\n",
      "\n",
      "    accuracy                           0.91      4200\n",
      "   macro avg       0.88      0.90      0.89      4200\n",
      "weighted avg       0.91      0.91      0.91      4200\n",
      "\n",
      "epoch 74 train loss is 0.2321 train AUC is 0.9707\n",
      "test LogLoss is 0.2285 test AUC is 0.9659\n",
      "f1_score :0.906483078311252\n",
      "epoch 75 train loss is 0.2317 train AUC is 0.9708\n",
      "test LogLoss is 0.2262 test AUC is 0.9655\n",
      "f1_score :0.9058178871754871\n",
      "epoch 76 train loss is 0.2309 train AUC is 0.9709\n",
      "test LogLoss is 0.2293 test AUC is 0.9656\n",
      "f1_score :0.9054568107440182\n",
      "epoch 77 train loss is 0.2305 train AUC is 0.9712\n",
      "test LogLoss is 0.2372 test AUC is 0.9655\n",
      "f1_score :0.9035156026347784\n",
      "epoch 78 train loss is 0.2314 train AUC is 0.9709\n",
      "test LogLoss is 0.2264 test AUC is 0.9662\n",
      "f1_score :0.9059791900525297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79 train loss is 0.2298 train AUC is 0.9715\n",
      "test LogLoss is 0.2197 test AUC is 0.9653\n",
      "f1_score :0.9094755064702977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      2967\n",
      "           1       0.83      0.87      0.85      1233\n",
      "\n",
      "    accuracy                           0.91      4200\n",
      "   macro avg       0.89      0.90      0.89      4200\n",
      "weighted avg       0.91      0.91      0.91      4200\n",
      "\n",
      "epoch 80 train loss is 0.2305 train AUC is 0.9712\n",
      "test LogLoss is 0.2245 test AUC is 0.9661\n",
      "f1_score :0.9067392926542063\n",
      "epoch 81 train loss is 0.2292 train AUC is 0.9715\n",
      "test LogLoss is 0.2293 test AUC is 0.9660\n",
      "f1_score :0.9070376747062462\n",
      "epoch 82 train loss is 0.2293 train AUC is 0.9714\n",
      "test LogLoss is 0.2329 test AUC is 0.9662\n",
      "f1_score :0.9050588699494951\n",
      "epoch 83 train loss is 0.2294 train AUC is 0.9715\n",
      "test LogLoss is 0.2241 test AUC is 0.9665\n",
      "f1_score :0.908271992558092\n",
      "epoch 84 train loss is 0.2294 train AUC is 0.9715\n",
      "test LogLoss is 0.2237 test AUC is 0.9664\n",
      "f1_score :0.9075065083531304\n",
      "epoch 85 train loss is 0.2291 train AUC is 0.9716\n",
      "test LogLoss is 0.2321 test AUC is 0.9662\n",
      "f1_score :0.9045570576951689\n",
      "epoch 86 train loss is 0.2288 train AUC is 0.9717\n",
      "test LogLoss is 0.2340 test AUC is 0.9666\n",
      "f1_score :0.9042248134198274\n",
      "epoch 87 train loss is 0.2285 train AUC is 0.9718\n",
      "test LogLoss is 0.2273 test AUC is 0.9666\n",
      "f1_score :0.9066034142327963\n",
      "epoch 88 train loss is 0.2277 train AUC is 0.9720\n",
      "test LogLoss is 0.2213 test AUC is 0.9663\n",
      "f1_score :0.9084928904541049\n",
      "epoch 89 train loss is 0.2278 train AUC is 0.9720\n",
      "test LogLoss is 0.2319 test AUC is 0.9663\n",
      "f1_score :0.9050588699494951\n",
      "epoch 90 train loss is 0.2286 train AUC is 0.9717\n",
      "test LogLoss is 0.2222 test AUC is 0.9668\n",
      "f1_score :0.9083390371657273\n",
      "epoch 91 train loss is 0.2272 train AUC is 0.9721\n",
      "test LogLoss is 0.2214 test AUC is 0.9669\n",
      "f1_score :0.9103925628401048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      2967\n",
      "           1       0.82      0.89      0.85      1233\n",
      "\n",
      "    accuracy                           0.91      4200\n",
      "   macro avg       0.88      0.90      0.89      4200\n",
      "weighted avg       0.91      0.91      0.91      4200\n",
      "\n",
      "epoch 92 train loss is 0.2276 train AUC is 0.9720\n",
      "test LogLoss is 0.2248 test AUC is 0.9666\n",
      "f1_score :0.907785294701304\n",
      "epoch 93 train loss is 0.2275 train AUC is 0.9722\n",
      "test LogLoss is 0.2203 test AUC is 0.9667\n",
      "f1_score :0.9086825836155985\n",
      "epoch 94 train loss is 0.2277 train AUC is 0.9720\n",
      "test LogLoss is 0.2266 test AUC is 0.9669\n",
      "f1_score :0.9079235263351912\n",
      "epoch 95 train loss is 0.2272 train AUC is 0.9722\n",
      "test LogLoss is 0.2237 test AUC is 0.9669\n",
      "f1_score :0.908219566747178\n",
      "epoch 96 train loss is 0.2264 train AUC is 0.9724\n",
      "test LogLoss is 0.2237 test AUC is 0.9667\n",
      "f1_score :0.906430547156248\n",
      "epoch 97 train loss is 0.2272 train AUC is 0.9723\n",
      "test LogLoss is 0.2212 test AUC is 0.9667\n",
      "f1_score :0.9079583391295946\n",
      "epoch 98 train loss is 0.2272 train AUC is 0.9723\n",
      "test LogLoss is 0.2232 test AUC is 0.9671\n",
      "f1_score :0.9054925075287418\n",
      "epoch 99 train loss is 0.2260 train AUC is 0.9726\n",
      "test LogLoss is 0.2223 test AUC is 0.9667\n",
      "f1_score :0.9062512420504286\n",
      "epoch 100 train loss is 0.2258 train AUC is 0.9726\n",
      "test LogLoss is 0.2290 test AUC is 0.9673\n",
      "f1_score :0.9080577338173049\n",
      "epoch 101 train loss is 0.2263 train AUC is 0.9725\n",
      "test LogLoss is 0.2244 test AUC is 0.9665\n",
      "f1_score :0.906864401651055\n",
      "epoch 102 train loss is 0.2248 train AUC is 0.9728\n",
      "test LogLoss is 0.2206 test AUC is 0.9661\n",
      "f1_score :0.9077040626642565\n",
      "epoch 103 train loss is 0.2252 train AUC is 0.9728\n",
      "test LogLoss is 0.2225 test AUC is 0.9670\n",
      "f1_score :0.9072806364837219\n",
      "epoch 104 train loss is 0.2255 train AUC is 0.9728\n",
      "test LogLoss is 0.2267 test AUC is 0.9671\n",
      "f1_score :0.9065693506493508\n",
      "epoch 105 train loss is 0.2246 train AUC is 0.9730\n",
      "test LogLoss is 0.2261 test AUC is 0.9665\n",
      "f1_score :0.9078376065975075\n",
      "epoch 106 train loss is 0.2247 train AUC is 0.9729\n",
      "test LogLoss is 0.2210 test AUC is 0.9671\n",
      "f1_score :0.9095230250153757\n",
      "epoch 107 train loss is 0.2237 train AUC is 0.9732\n",
      "test LogLoss is 0.2280 test AUC is 0.9665\n",
      "f1_score :0.9058409568550931\n",
      "epoch 108 train loss is 0.2241 train AUC is 0.9731\n",
      "test LogLoss is 0.2227 test AUC is 0.9672\n",
      "f1_score :0.9078549169342748\n",
      "epoch 109 train loss is 0.2246 train AUC is 0.9729\n",
      "test LogLoss is 0.2319 test AUC is 0.9669\n",
      "f1_score :0.9023560292914341\n",
      "epoch 110 train loss is 0.2250 train AUC is 0.9730\n",
      "test LogLoss is 0.2219 test AUC is 0.9673\n",
      "f1_score :0.9063952046820428\n",
      "epoch 111 train loss is 0.2243 train AUC is 0.9731\n",
      "test LogLoss is 0.2282 test AUC is 0.9673\n",
      "f1_score :0.9043997299017655\n",
      "epoch 112 train loss is 0.2242 train AUC is 0.9732\n",
      "test LogLoss is 0.2206 test AUC is 0.9665\n",
      "f1_score :0.9089452417660259\n",
      "epoch 113 train loss is 0.2237 train AUC is 0.9732\n",
      "test LogLoss is 0.2192 test AUC is 0.9673\n",
      "f1_score :0.9083747898377846\n",
      "epoch 114 train loss is 0.2226 train AUC is 0.9735\n",
      "test LogLoss is 0.2225 test AUC is 0.9663\n",
      "f1_score :0.9073442591133791\n",
      "epoch 115 train loss is 0.2236 train AUC is 0.9733\n",
      "test LogLoss is 0.2200 test AUC is 0.9671\n",
      "f1_score :0.9072270958461781\n",
      "epoch 116 train loss is 0.2228 train AUC is 0.9736\n",
      "test LogLoss is 0.2198 test AUC is 0.9673\n",
      "f1_score :0.9081842982536622\n",
      "epoch 117 train loss is 0.2228 train AUC is 0.9735\n",
      "test LogLoss is 0.2195 test AUC is 0.9668\n",
      "f1_score :0.9088090933853901\n",
      "epoch 118 train loss is 0.2230 train AUC is 0.9735\n",
      "test LogLoss is 0.2201 test AUC is 0.9669\n",
      "f1_score :0.9086539437868918\n",
      "epoch 119 train loss is 0.2222 train AUC is 0.9737\n",
      "test LogLoss is 0.2175 test AUC is 0.9663\n",
      "f1_score :0.9081936158060606\n",
      "epoch 120 train loss is 0.2222 train AUC is 0.9736\n",
      "test LogLoss is 0.2230 test AUC is 0.9666\n",
      "f1_score :0.9070191385084678\n",
      "epoch 121 train loss is 0.2219 train AUC is 0.9736\n",
      "test LogLoss is 0.2197 test AUC is 0.9670\n",
      "f1_score :0.907886981153952\n",
      "epoch 122 train loss is 0.2224 train AUC is 0.9737\n",
      "test LogLoss is 0.2175 test AUC is 0.9668\n",
      "f1_score :0.9083826232247284\n",
      "epoch 123 train loss is 0.2217 train AUC is 0.9739\n",
      "test LogLoss is 0.2208 test AUC is 0.9666\n",
      "f1_score :0.9080950077894517\n",
      "epoch 124 train loss is 0.2216 train AUC is 0.9738\n",
      "test LogLoss is 0.2208 test AUC is 0.9664\n",
      "f1_score :0.9069106194566439\n",
      "epoch 125 train loss is 0.2217 train AUC is 0.9739\n",
      "test LogLoss is 0.2183 test AUC is 0.9667\n",
      "f1_score :0.9075721273050853\n",
      "epoch 126 train loss is 0.2208 train AUC is 0.9739\n",
      "test LogLoss is 0.2184 test AUC is 0.9673\n",
      "f1_score :0.9078327868931033\n",
      "epoch 127 train loss is 0.2219 train AUC is 0.9739\n",
      "test LogLoss is 0.2200 test AUC is 0.9670\n",
      "f1_score :0.9073442591133791\n",
      "epoch 128 train loss is 0.2214 train AUC is 0.9739\n",
      "test LogLoss is 0.2238 test AUC is 0.9673\n",
      "f1_score :0.906204854641517\n",
      "epoch 129 train loss is 0.2202 train AUC is 0.9742\n",
      "test LogLoss is 0.2295 test AUC is 0.9669\n",
      "f1_score :0.9059437252319809\n",
      "epoch 130 train loss is 0.2206 train AUC is 0.9742\n",
      "test LogLoss is 0.2238 test AUC is 0.9665\n",
      "f1_score :0.9084455285728956\n",
      "epoch 131 train loss is 0.2212 train AUC is 0.9740\n",
      "test LogLoss is 0.2223 test AUC is 0.9672\n",
      "f1_score :0.9059437999326821\n",
      "epoch 132 train loss is 0.2198 train AUC is 0.9744\n",
      "test LogLoss is 0.2257 test AUC is 0.9672\n",
      "f1_score :0.9055980408557558\n",
      "epoch 133 train loss is 0.2203 train AUC is 0.9742\n",
      "test LogLoss is 0.2210 test AUC is 0.9671\n",
      "f1_score :0.9089150386827783\n",
      "epoch 134 train loss is 0.2196 train AUC is 0.9744\n",
      "test LogLoss is 0.2204 test AUC is 0.9673\n",
      "f1_score :0.9088269099176873\n",
      "epoch 135 train loss is 0.2196 train AUC is 0.9745\n",
      "test LogLoss is 0.2306 test AUC is 0.9667\n",
      "f1_score :0.9063778351189967\n",
      "epoch 136 train loss is 0.2198 train AUC is 0.9744\n",
      "test LogLoss is 0.2177 test AUC is 0.9668\n",
      "f1_score :0.9060274207369323\n",
      "epoch 137 train loss is 0.2193 train AUC is 0.9744\n",
      "test LogLoss is 0.2185 test AUC is 0.9673\n",
      "f1_score :0.9081487743773164\n",
      "epoch 138 train loss is 0.2198 train AUC is 0.9744\n",
      "test LogLoss is 0.2226 test AUC is 0.9670\n",
      "f1_score :0.9071077933283496\n",
      "epoch 139 train loss is 0.2187 train AUC is 0.9747\n",
      "test LogLoss is 0.2208 test AUC is 0.9672\n",
      "f1_score :0.9061159530125048\n",
      "epoch 140 train loss is 0.2184 train AUC is 0.9748\n",
      "test LogLoss is 0.2186 test AUC is 0.9667\n",
      "f1_score :0.9085110418498709\n",
      "epoch 141 train loss is 0.2207 train AUC is 0.9742\n",
      "test LogLoss is 0.2316 test AUC is 0.9663\n",
      "f1_score :0.9061692407668389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 142 train loss is 0.2190 train AUC is 0.9746\n",
      "test LogLoss is 0.2242 test AUC is 0.9673\n",
      "f1_score :0.9078893478103308\n",
      "epoch 143 train loss is 0.2191 train AUC is 0.9747\n",
      "test LogLoss is 0.2238 test AUC is 0.9675\n",
      "f1_score :0.9074720251563859\n",
      "epoch 144 train loss is 0.2181 train AUC is 0.9749\n",
      "test LogLoss is 0.2182 test AUC is 0.9672\n",
      "f1_score :0.9082667607758226\n",
      "epoch 145 train loss is 0.2187 train AUC is 0.9747\n",
      "test LogLoss is 0.2196 test AUC is 0.9671\n",
      "f1_score :0.9079049169651577\n",
      "epoch 146 train loss is 0.2175 train AUC is 0.9751\n",
      "test LogLoss is 0.2178 test AUC is 0.9665\n",
      "f1_score :0.9097982432230101\n",
      "epoch 147 train loss is 0.2192 train AUC is 0.9746\n",
      "test LogLoss is 0.2149 test AUC is 0.9662\n",
      "f1_score :0.9113411037010294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      2967\n",
      "           1       0.84      0.86      0.85      1233\n",
      "\n",
      "    accuracy                           0.91      4200\n",
      "   macro avg       0.89      0.90      0.89      4200\n",
      "weighted avg       0.91      0.91      0.91      4200\n",
      "\n",
      "epoch 148 train loss is 0.2181 train AUC is 0.9749\n",
      "test LogLoss is 0.2174 test AUC is 0.9674\n",
      "f1_score :0.9094518023449879\n",
      "epoch 149 train loss is 0.2169 train AUC is 0.9752\n",
      "test LogLoss is 0.2194 test AUC is 0.9670\n",
      "f1_score :0.9078327868931033\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_model_input, np.array(train_y) , \n",
    "          test_model_input , np.array(test_y)\n",
    "          ,batch_size=256, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f30f7",
   "metadata": {},
   "source": [
    "### model merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05748b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_pred =bst.predict(test_x).tolist()\n",
    "rf_y_pred =clf.predict(test_x).tolist()\n",
    "df_y_pred =model.predict(test_xx,128)\n",
    "df_y_pred =df_y_pred.reshape((1,-1)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f556fc45",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-dfd54d9367c6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['xgb'] =xgb_y_pred\n",
      "<ipython-input-39-dfd54d9367c6>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['rf'] =rf_y_pred\n",
      "<ipython-input-39-dfd54d9367c6>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['df'] =[1 if i >0.55 else 0 for i in df_y_pred]\n",
      "<ipython-input-39-dfd54d9367c6>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['ground_truth'] = test_y\n"
     ]
    }
   ],
   "source": [
    "test_x['xgb'] =xgb_y_pred\n",
    "test_x['rf'] =rf_y_pred\n",
    "test_x['df'] =[1 if i >0.55 else 0 for i in df_y_pred]\n",
    "test_x['ground_truth'] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4aae5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(value_list):\n",
    "    label_sum = sum(value_list)\n",
    "    label =0\n",
    "    if label_sum >=2:\n",
    "        label =1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "548eaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-ec24e029e2ea>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['merged_label'] = test_x.apply(lambda x : label([x.xgb,x.rf,x.df]),axis=1)\n"
     ]
    }
   ],
   "source": [
    "test_x['merged_label'] = test_x.apply(lambda x : label([x.xgb,x.rf,x.df]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1907c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2967\n",
      "           1       0.94      0.95      0.95      1233\n",
      "\n",
      "    accuracy                           0.97      4200\n",
      "   macro avg       0.96      0.96      0.96      4200\n",
      "weighted avg       0.97      0.97      0.97      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_x['ground_truth'],test_x['merged_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b30db",
   "metadata": {},
   "source": [
    "### model redict result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd601e73",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-b454025050dd>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['correct_flag'] = test_x['ground_truth'] ==test_x['xgb']\n",
      "<ipython-input-63-b454025050dd>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['trans_deposit_ratio'] = test_x['TRAN_AMT']/(test_x['ACCT_PRE_TRAN_AVAIL_BAL']+test_x['TRAN_AMT'])\n"
     ]
    }
   ],
   "source": [
    "test_x['correct_flag'] = test_x['ground_truth'] ==test_x['xgb']\n",
    "\n",
    "test_x['trans_deposit_ratio'] = test_x['TRAN_AMT']/(test_x['ACCT_PRE_TRAN_AVAIL_BAL']+test_x['TRAN_AMT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f86acc87",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-d5afabd59eaf>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x['trans_deposit_ratio_cls'] =pd.cut(test_x['trans_deposit_ratio'],bins=[i/10 for i in range(0,11)])\n"
     ]
    }
   ],
   "source": [
    "test_x['trans_deposit_ratio_cls'] =pd.cut(test_x['trans_deposit_ratio'],bins=[i/10 for i in range(0,11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "701a6183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>correct_flag</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_deposit_ratio_cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.1]</th>\n",
       "      <td>99</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 0.2]</th>\n",
       "      <td>19</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.2, 0.3]</th>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.3, 0.4]</th>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.4, 0.5]</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.5, 0.6]</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.6, 0.7]</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.7, 0.8]</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.8, 0.9]</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.9, 1.0]</th>\n",
       "      <td>0</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "correct_flag             False  True \n",
       "trans_deposit_ratio_cls              \n",
       "(0.0, 0.1]                  99   1709\n",
       "(0.1, 0.2]                  19    878\n",
       "(0.2, 0.3]                  10    162\n",
       "(0.3, 0.4]                   3     62\n",
       "(0.4, 0.5]                   4     31\n",
       "(0.5, 0.6]                   0     29\n",
       "(0.6, 0.7]                   0     24\n",
       "(0.7, 0.8]                   0     29\n",
       "(0.8, 0.9]                   0     15\n",
       "(0.9, 1.0]                   0   1126"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(data=test_x,index='trans_deposit_ratio_cls',columns='correct_flag',values ='xgb',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35fddf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]    46\n",
       "(0.1, 0.2]    14\n",
       "(0.2, 0.3]     8\n",
       "(0.4, 0.5]     2\n",
       "(0.3, 0.4]     1\n",
       "(0.5, 0.6]     0\n",
       "(0.6, 0.7]     0\n",
       "(0.7, 0.8]     0\n",
       "(0.8, 0.9]     0\n",
       "(0.9, 1.0]     0\n",
       "Name: trans_deposit_ratio_cls, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groud truth ==non-fraud; predict result ==fraud\n",
    "test_x[(test_x['correct_flag']==False)&\n",
    "      (test_x['xgb']==1)]['trans_deposit_ratio_cls'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15c8d22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]    53\n",
       "(0.1, 0.2]     5\n",
       "(0.2, 0.3]     2\n",
       "(0.3, 0.4]     2\n",
       "(0.4, 0.5]     2\n",
       "(0.5, 0.6]     0\n",
       "(0.6, 0.7]     0\n",
       "(0.7, 0.8]     0\n",
       "(0.8, 0.9]     0\n",
       "(0.9, 1.0]     0\n",
       "Name: trans_deposit_ratio_cls, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groud truth == fraud; predict result ==non-fraud\n",
    "test_x[(test_x['correct_flag']==False)&\n",
    "      (test_x['xgb']==0)]['trans_deposit_ratio_cls'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de341114",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "\n",
    "\n",
    "1. we use three different models(random forest,xgboost,DeepFM), the classification result show that random forest and xgboost have similar performance, both get f1 score 96. however,the f1 score of DeepFM is the lowest among the three, probably due to limited number of dataset.\n",
    "\n",
    "\n",
    "\n",
    "2. we also merge the predict result of the three, however, the performance does not improve.\n",
    "\n",
    "\n",
    "\n",
    "3. Comparing the performance of random forest and xgboost, we finnaly choose xgboost on ground of common sense that  higher recall score of fraud  is more importance in reality.\n",
    "\n",
    "4. the classificaiton report(\"0\" equals to\"non-fraud\";\"1\" equals to \"fraud\") on xgboost shows that:\n",
    "\n",
    "    a.The model performs better than \"fraud\" in predicting \"non-fraud\" transactions, with higher precision and recall. For example, out of 100 transactions predicted by the model to be fraudulent, there is a probability of error for 6 times; and out of 100 transactions predicted by the model to be non-fraud, the probability of error is 2 times.\n",
    "\n",
    "    b. In terms of feature importance, the derived features from \"RGN_NAME\", \"STATE_PRVNC_TXT\" and \"DVC_TYPE_TXT\",and the original feature \"TRAN_AMT\" contribute significantly to the model classification results.\n",
    "\n",
    "    c. On the test data set, when the transaction amount accounts for less than 10% of the account balance, the prediction error probability of the model increases;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
